{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1- Import Raw Unstructured Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of \"/Users/zaahirdawood/Desktop/Unstructured to Structured data/data/Philosopher Unstructured Data.zip\" have been extracted to \"/Users/zaahirdawood/Desktop/Unstructured to Structured data/data/\"\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "# Specify the path to the zip file you want to unzip\n",
    "zip_file_path = '/Users/zaahirdawood/Desktop/Unstructured to Structured data/data/Philosopher Unstructured Data.zip'\n",
    "\n",
    "# Specify the directory where you want to extract the contents\n",
    "extract_dir = '/Users/zaahirdawood/Desktop/Unstructured to Structured data/data/'\n",
    "\n",
    "# Create a ZipFile object and open the zip file for reading\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    # Extract all the contents of the zip file to the specified directory\n",
    "    zip_ref.extractall(extract_dir)\n",
    "\n",
    "print(f'Contents of \"{zip_file_path}\" have been extracted to \"{extract_dir}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in unstructured data\n",
    "with open('/Users/zaahirdawood/Desktop/Unstructured to Structured data/data/aristotle.txt', 'r', encoding='utf-8') as f:\n",
    "  aristotle_corpus = f.read()\n",
    "with open( '/Users/zaahirdawood/Desktop/Unstructured to Structured data/data/kant.txt', 'r', encoding='utf-8') as f:\n",
    "  kant_corpus = f.read()\n",
    "with open('/Users/zaahirdawood/Desktop/Unstructured to Structured data/data/nietzsche.txt', 'r', encoding='utf-8') as f:\n",
    "  nietzsche_corpus = f.read()  \n",
    "with open('/Users/zaahirdawood/Desktop/Unstructured to Structured data/data/plato.txt', 'r', encoding='utf-8') as f:\n",
    "  plato_corpus = f.read()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview a sample from the corpus data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What I am now going to relate is the history of the next two centuries.\n",
      "I shall describe what will happen, what must necessarily happen:\n",
      "_the triumph of Nihilism._ This history can be written already; for\n",
      "necessity itself is at work in bringing it about. This future is\n",
      "already proclaimed by a hundred different omens; as a destiny it\n",
      "announces its advent everywhere, for this music of to-morrow all ears\n",
      "are already pricked. The whole of our culture in Europe has long\n",
      "been writhing in an agony of suspense which increases from decade\n",
      "to decade as if in expectation of a catastrophe: restless, violent,\n",
      "helter-skelter, like a torrent that will _reach its bourne,_ and\n",
      "refuses to reflect--yea, that even dreads reflection.\n",
      "\n",
      "\n",
      "3.\n",
      "\n",
      "On the other hand, the present writer has done little else, hitherto,\n",
      "than _reflect and meditate,_ like an instinctive philosopher and\n",
      "anchorite, who found his advantage in isolation--in remaining outside,\n",
      "in patience, procrastination, and lagging behind; like a weighing and\n",
      "testing spirit who has already lost his way in every labyrinth of\n",
      "the future; like a prophetic bird-spirit that _looks backwards_ when\n",
      "it would announce what is to come; like the first perfect European\n",
      "Nihilist, who, however, has already outlived Nihilism in his own\n",
      "soul--who has out-grown, overcome, and dismissed it.\n",
      "\n",
      "\n",
      "4.\n",
      "\n",
      "For the reader must not misunderstand the meaning of the title which\n",
      "has been given to this Evangel of the Future. \"_The Will to Power:\n",
      "An Attempted Transvaluation of all Values_\"--with this formula a\n",
      "_counter-movement_ finds expression, in regard to both a principle and\n",
      "a mission; a movement which in some remote future will supersede this\n",
      "perfect Nihilism; but which nevertheless regards it as a _necessary\n",
      "step,_ both logically and psychologically, towards its own advent,\n",
      "and which positively cannot come, except _on top of_ and _out of_ it.\n",
      "For, why is the triumph of Nihilism _inevitable_ now? Because the\n",
      "very values current amongst us to-day will arrive at th\n"
     ]
    }
   ],
   "source": [
    "print(nietzsche_corpus[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2- Create a Book Processor class that will keep functions/methods to clean book data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp_python/lib/python3.7/site-packages/sklearn/utils/validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/zaahirdawood/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/zaahirdawood/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "#Download stopwords to workingspace\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "# Use english stopwords\n",
    "sw = set(stopwords.words('english'))\n",
    "# Load spacy english library object\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "class BookProcessor:\n",
    "    def __init__(self,sw):\n",
    "        self.sw = sw\n",
    "   # lowercase the text data     \n",
    "    def lower_case_clean(self, text):\n",
    "        text = re.sub(\"Part\", \"\", text)\n",
    "        text = text.lower()\n",
    "        return re.sub(\"\\n\", \" \", text)\n",
    "    # use regex to clean book formatting\n",
    "    def clean_up(self, text):\n",
    "        text = text.replace(' ', ' ')\n",
    "        text = text.replace('–', '-')\n",
    "        text = text.replace('\\n', ' ')\n",
    "        text = re.sub(r'[IVXLCDM]+\\.', '', text)\n",
    "        text = re.sub(r'\\[[^]]*\\]', '', text)\n",
    "        text = re.sub(r':', '', text)\n",
    "        text = re.sub(r'\\((.*?)\\)', '', text)\n",
    "        text = re.sub(r'\\{(.*?)\\}', '', text)\n",
    "        text = re.sub(r'\\b[A-Z]{2,}\\b', '', text)\n",
    "        text = text.replace(' ,', ',')\n",
    "        text = text.replace(' .', '.')\n",
    "        text = text.replace(' ;', ';')\n",
    "        text = re.sub(r'[^A-Za-z0-9äÄöÖüÜß\\s\\.\\-\\!\\?\\:\\;\\,]', '', text)\n",
    "        text = re.sub(r' +', ' ', text)\n",
    "        return text\n",
    "    #remove stop words\n",
    "    def remove_stop_words(self, text):\n",
    "        text = [word.lower() for word in text.split() if word.lower() not in self.sw]\n",
    "        return \" \".join(text)\n",
    "\n",
    "    #remove punctuation\n",
    "    def remove_punct(self, text):\n",
    "        table = str.maketrans(\"\", \"\", string.punctuation)\n",
    "        return text.translate(table)\n",
    "\n",
    "    #remove bookmarks from plato corpus\n",
    "    def clean_plato_corpus(self, word):\n",
    "        word = re.sub(\"gutenbergtm\", \"\", word)\n",
    "        word = re.sub(\"project\", \"\", word)\n",
    "        word = re.sub(\"electronic\", \"\", word)\n",
    "        word = re.sub(\"gutenberg\", \"\", word)\n",
    "        word = re.sub(\"literary\", \"\", word)\n",
    "        word = re.sub(\"archive\", \"\", word)\n",
    "        word = re.sub(\"foundation\", \"\", word)\n",
    "        return word\n",
    "    #generate tokens from text \n",
    "    def tokenize_sentences(self, text):\n",
    "        text = text.split(sep='.')\n",
    "        return text\n",
    "        \n",
    "        return word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate and use methods to clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the BookProcessor class\n",
    "process = BookProcessor(sw)\n",
    "\n",
    "def clean_text(process, text):\n",
    "    text = process.clean_up(text)\n",
    "    text = process.remove_stop_words(text)\n",
    "    return text\n",
    "\n",
    "def clean_all_corpus_text():\n",
    "    # 1. Cleaning Kant Text\n",
    "    cleaned_kant_corpus = clean_text(process, kant_corpus)\n",
    "    # 2. Cleaning Aristotle Text\n",
    "    cleaned_aristotle_corpus = clean_text(process, aristotle_corpus)\n",
    "    # 3. Cleaning Nietzsche Text\n",
    "    cleaned_nietzsche_corpus = clean_text(process, nietzsche_corpus)\n",
    "    # 4. Cleaning Plato Text\n",
    "    clean_plato_corpus = clean_text(process, plato_corpus)\n",
    "    cleaned_plato_corpus = process.clean_plato_corpus(clean_plato_corpus)\n",
    "\n",
    "    \n",
    "    return cleaned_kant_corpus, cleaned_aristotle_corpus, cleaned_plato_corpus,cleaned_nietzsche_corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean all corpus text\n",
    "cleaned_kant_corpus, cleaned_aristotle_corpus, cleaned_plato_corpus,cleaned_nietzsche_corpus = clean_all_corpus_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of the cleaned text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "things said named equivocally when, though common name, definition corresponding name differs each. thus, real man figure picture lay claim name animal; yet equivocally named, for, though common name, definition corresponding name differs each. one define sense animal, definition one case appropriate case only. hand, things said named univocally name definition answering name common. man ox animal, univocally named, inasmuch name, also definition, cases man state sense animal, statement one case would identical other. things said named derivatively, derive name name, differ termination. thus grammarian derives name word grammar, courageous man word courage. part 2 forms speech either simple composite. examples latter expressions man runs, man wins; former man, ox, runs, wins. things predicable subject, never present subject. thus man predicable individual man, never present subject. present subject mean present parts present whole, incapable existence apart said subject. things, again,\n"
     ]
    }
   ],
   "source": [
    "# example of lowercased words, removed stopwords,\n",
    "print(cleaned_aristotle_corpus[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Generate Sentence Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pack all functions for processing tokens into the generate tokens function\n",
    "def generate_tokens():\n",
    "    aristotle_sents = process.tokenize_sentences(cleaned_aristotle_corpus)\n",
    "    kant_sents = process.tokenize_sentences(cleaned_kant_corpus)\n",
    "    plato_sents = process.tokenize_sentences(cleaned_plato_corpus)\n",
    "    nietzsche_sents = process.tokenize_sentences(cleaned_nietzsche_corpus)\n",
    "    return aristotle_sents, kant_sents,plato_sents,nietzsche_sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use function to generate tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "aristotle_sents, kant_sents, plato_sents, nietzsche_sents = generate_tokens()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Create a dataframe which is a table like data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aristotle</td>\n",
       "      <td>things said named equivocally when, though com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aristotle</td>\n",
       "      <td>thus, real man figure picture lay claim name ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aristotle</td>\n",
       "      <td>one define sense animal, definition one case ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aristotle</td>\n",
       "      <td>hand, things said named univocally name defin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aristotle</td>\n",
       "      <td>man ox animal, univocally named, inasmuch nam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      author                                           sentence\n",
       "0  Aristotle  things said named equivocally when, though com...\n",
       "1  Aristotle   thus, real man figure picture lay claim name ...\n",
       "2  Aristotle   one define sense animal, definition one case ...\n",
       "3  Aristotle   hand, things said named univocally name defin...\n",
       "4  Aristotle   man ox animal, univocally named, inasmuch nam..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aris = pd.DataFrame({ 'author':'Aristotle','sentence': aristotle_sents})\n",
    "niet = pd.DataFrame({ 'author':'Nietzsche','sentence': nietzsche_sents})\n",
    "kant = pd.DataFrame({'author':'Kant','sentence':kant_sents})\n",
    "Plat = pd.DataFrame({'author':'Plato','sentence':plato_sents})\n",
    "# Make a list of lists\n",
    "frames = [aris,niet,kant,Plat]\n",
    "# Concatenante frames into a single dataframe\n",
    "philo = pd.concat(frames)\n",
    "\n",
    "philo.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude sentences with less than 4 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65898\n",
      "46471\n"
     ]
    }
   ],
   "source": [
    "# Getting length of dataframe before removing additional sentences\n",
    "print(len(philo))\n",
    "# Getting Sentence Length\n",
    "philo['sent_len'] = philo['sentence'].apply(lambda x: len(x))\n",
    "# Dropping Sentences that are less than 4 words\n",
    "philo = philo.drop(philo[philo['sent_len'] < 4].index)\n",
    "# Removing punctuation from sentences\n",
    "philo.sentence = philo.sentence.map(process.remove_punct)\n",
    "# Checking length of dataframe afer sentences have been removed\n",
    "print(len(philo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract sample of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sent_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8010</th>\n",
       "      <td>Aristotle</td>\n",
       "      <td>thus kingly power unequal exercised equals</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13542</th>\n",
       "      <td>Plato</td>\n",
       "      <td>state hand created nearest immortality one ta...</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14726</th>\n",
       "      <td>Nietzsche</td>\n",
       "      <td>it little true martyrs offer support truth ca...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17852</th>\n",
       "      <td>Plato</td>\n",
       "      <td>cannot however become already become would me...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332</th>\n",
       "      <td>Nietzsche</td>\n",
       "      <td>creates goal stands mankind kind individual f...</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17859</th>\n",
       "      <td>Plato</td>\n",
       "      <td>since one partakes time partakes becoming old...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8292</th>\n",
       "      <td>Kant</td>\n",
       "      <td>substances substratum determinations time</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16479</th>\n",
       "      <td>Nietzsche</td>\n",
       "      <td>3 double thread experiences means access two ...</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20147</th>\n",
       "      <td>Nietzsche</td>\n",
       "      <td>often came him tells friends prison one dream...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9266</th>\n",
       "      <td>Aristotle</td>\n",
       "      <td>values real worth smallminded whether worth g...</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          author                                           sentence  sent_len\n",
       "8010   Aristotle         thus kingly power unequal exercised equals        43\n",
       "13542      Plato   state hand created nearest immortality one ta...       101\n",
       "14726  Nietzsche   it little true martyrs offer support truth ca...        96\n",
       "17852      Plato   cannot however become already become would me...        60\n",
       "2332   Nietzsche   creates goal stands mankind kind individual f...       131\n",
       "17859      Plato   since one partakes time partakes becoming old...       111\n",
       "8292        Kant          substances substratum determinations time        42\n",
       "16479  Nietzsche   3 double thread experiences means access two ...       148\n",
       "20147  Nietzsche   often came him tells friends prison one dream...       111\n",
       "9266   Aristotle   values real worth smallminded whether worth g...        88"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp =philo.sample(n=10)\n",
    "samp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Extract Features from Text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count occurrences of a specific POS tag in a text\n",
    "def count_specific_pos(text, target_pos):\n",
    "    doc = nlp(text)\n",
    "    pos_count = 0\n",
    "    for token in doc:\n",
    "        if token.pos_ == target_pos:\n",
    "            pos_count += 1\n",
    "    return pos_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Text Based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Define the specific POS tag you want to count (e.g., \"NOUN\" for nouns)\n",
    "target_pos = [\"VERB\",\"NOUN\",\"PROPN\"]\n",
    "\n",
    "for pos in target_pos:\n",
    "    samp[f'{pos}_Count'] = samp['sentence'].apply(lambda x: count_specific_pos(x, pos))\n",
    "\n",
    "#Initialise dummy persuasion score\n",
    "samp['persuasion_score'] = 0\n",
    "\n",
    "#Assign random value to persusaion score\n",
    "samp['persuasion_score']= samp['persuasion_score'].apply(lambda x: random.randint(1,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showcase final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sent_len</th>\n",
       "      <th>VERB_Count</th>\n",
       "      <th>NOUN_Count</th>\n",
       "      <th>PROPN_Count</th>\n",
       "      <th>persuasion_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8010</th>\n",
       "      <td>Aristotle</td>\n",
       "      <td>thus kingly power unequal exercised equals</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13542</th>\n",
       "      <td>Plato</td>\n",
       "      <td>state hand created nearest immortality one ta...</td>\n",
       "      <td>101</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14726</th>\n",
       "      <td>Nietzsche</td>\n",
       "      <td>it little true martyrs offer support truth ca...</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17852</th>\n",
       "      <td>Plato</td>\n",
       "      <td>cannot however become already become would me...</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332</th>\n",
       "      <td>Nietzsche</td>\n",
       "      <td>creates goal stands mankind kind individual f...</td>\n",
       "      <td>131</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          author                                           sentence  sent_len  \\\n",
       "8010   Aristotle         thus kingly power unequal exercised equals        43   \n",
       "13542      Plato   state hand created nearest immortality one ta...       101   \n",
       "14726  Nietzsche   it little true martyrs offer support truth ca...        96   \n",
       "17852      Plato   cannot however become already become would me...        60   \n",
       "2332   Nietzsche   creates goal stands mankind kind individual f...       131   \n",
       "\n",
       "       VERB_Count  NOUN_Count  PROPN_Count  persuasion_score  \n",
       "8010            1           2            0                 7  \n",
       "13542           3           6            0                 2  \n",
       "14726           1           8            0                 7  \n",
       "17852           5           0            0                 7  \n",
       "2332            3           9            0                 1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the DataFrame with the count of the specific POS tag & persuasion score\n",
    "samp.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
